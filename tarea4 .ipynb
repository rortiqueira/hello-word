{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subir archivo minisom.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1089ebc9ce9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muploaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "        name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from minisom import MiniSom\n",
    "\n",
    "class KMedians(KMeans):\n",
    "    def _e_step(self, X):\n",
    "        self.labels_ = manhattan_distances(X, self.cluster_centers_).argmin(axis=1)\n",
    "    def _average(self, X):\n",
    "        return np.median(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "country_data = pickle.load(open(\"country_normalized_exports.pkl\", \"rb\"))\n",
    "world_data = country_data['world_data']\n",
    "world_labels = country_data['world_labels']\n",
    "world_labels_short = country_data['world_labels_short']\n",
    "feature_names = country_data['feature_name']\n",
    "N, M = world_data.shape\n",
    "print(\"Nombres de paises y sus abreviaturas:\")\n",
    "I = np.argsort(world_labels_short)\n",
    "print(np.concatenate((np.asarray(world_labels_short)[I, np.newaxis], \n",
    "                      np.asarray(world_labels)[I, np.newaxis]), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupar exportaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = np.zeros((len(world_data), 15))\n",
    "indexes = [0, 5, 15, 24, 27, 38, 40, 43, 49, 63, 67, 71, 83, 85, 89, 97]\n",
    "for i in range(15):\n",
    "    start = indexes[i]\n",
    "    end = indexes[i+1]\n",
    "    grouped_data[:, i] = world_data[:, start:end].sum(axis=1)\n",
    "grouped_feature_names = [\n",
    "    'Animal & Animal Products',\n",
    "    'Vegetable Products',\n",
    "    'Foodstuffs',\n",
    "    'Mineral Products',\n",
    "    'Chemicals & Allied Industries',\n",
    "    'Plastics / Rubbers',\n",
    "    'Raw Hides, Skins, Leather & Furs',\n",
    "    'Wood & Wood Products',\n",
    "    'Textiles',\n",
    "    'Footwear / Headgear',\n",
    "    'Stone / Glass',\n",
    "    'Metals',\n",
    "    'Machinery / Electrical',\n",
    "    'Transportation',\n",
    "    'Miscellaneous'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar subconjunto de paises para etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_subset = ['are','arg','aus','aut','bgd',\n",
    "    'bgr','bhr','blr','blx','bol','bra','caf','can',\n",
    "    'chl','chn','civ','cmr','cod','cog','col','cub',\n",
    "    'deu','dnk','ecu','egy','esp','fin','fra','gbr',\n",
    "    'geo','gha','grc','hkg','hti','idn','ind','irl',\n",
    "    'irn','irq','isr','ita','jpn','kwt','mex','nld',\n",
    "    'nor','pak','per','pol','prk','prt','pry','pse',\n",
    "    'qat','rus','sau','sgp','ury','usa','yem','zaf',\n",
    "    'kaz','kor','idn','isl','sen','uzb','sur','flk',\n",
    "    'grl','tun','cri','kna','eth','afg','uga'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activar/Desactivar agrupación de productos\n",
    "\n",
    "Cambie el valor de la variable booleana is_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7bcff23e30f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mis_grouped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_grouped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mselected_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mselected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped_feature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grouped_data' is not defined"
     ]
    }
   ],
   "source": [
    "is_grouped = True\n",
    "if is_grouped:\n",
    "    selected_data = grouped_data\n",
    "    selected_features = grouped_feature_names\n",
    "else:\n",
    "    selected_data = world_data\n",
    "    selected_features = feature_names\n",
    "# Normalizar datos\n",
    "world_data_scaled = scale(selected_data, axis=0, with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering usando kmedians\n",
    "\n",
    "El parámetro n_clusters modifica el número de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = KMedians(n_clusters=7)\n",
    "pred_labels = clustering.fit_predict(world_data_scaled)\n",
    "print(\"Suma de errores cuadráticos: %f\" %(clustering.inertia_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_no_kernel_projection = pca.fit_transform(world_data_scaled)\n",
    "world_data_projected = pca_no_kernel_projection\n",
    "print(\"Varianza explicada por los primeros componentes principales:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Suma acumulada de los primeros componentes principales: %f\" % np.sum(pca.explained_variance_ratio_))\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(world_data_projected[:, 0], world_data_projected[:, 1], \n",
    "           c=pred_labels/clustering.n_clusters, linewidth=0, alpha=0.5, s=150, cmap='Set1')\n",
    "xscale = world_data_projected[:, 0].max() - world_data_projected[:, 0].min()\n",
    "yscale = world_data_projected[:, 1].max() - world_data_projected[:, 1].min()\n",
    "for i in range(N):\n",
    "    if world_labels_short[i] in countries_subset:\n",
    "        if world_labels_short[i] == \"chl\":\n",
    "            ax.annotate(world_labels_short[i], \n",
    "                        xy=(world_data_projected[i, 0]+0.01*xscale, world_data_projected[i, 1]+0.01*yscale), fontsize=12, color='r',\n",
    "                       bbox={'facecolor':'white', 'alpha':0.6, 'pad':2})\n",
    "        else:\n",
    "            ax.annotate(world_labels_short[i], \n",
    "                        xy=(world_data_projected[i, 0]+0.01*xscale, world_data_projected[i, 1]+0.01*yscale), fontsize=10,\n",
    "                       bbox={'facecolor':'white', 'alpha':0.6, 'pad':2})\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización con KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = KernelPCA(n_components=2, kernel=\"rbf\")\n",
    "pca_kernel_projection = pca.fit_transform(world_data_scaled) \n",
    "world_data_projected = pca_kernel_projection\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(world_data_projected[:, 0], world_data_projected[:, 1], \n",
    "           c=pred_labels/clustering.n_clusters, linewidth=0, alpha=0.5, s=150, cmap='Set1')\n",
    "xscale = world_data_projected[:, 0].max() - world_data_projected[:, 0].min()\n",
    "yscale = world_data_projected[:, 1].max() - world_data_projected[:, 1].min()\n",
    "for i in range(N):\n",
    "    if world_labels_short[i] in countries_subset:\n",
    "        if world_labels_short[i] == \"chl\":\n",
    "            ax.annotate(world_labels_short[i], \n",
    "                        xy=(world_data_projected[i, 0]+0.01*xscale, world_data_projected[i, 1]+0.01*yscale), fontsize=12, color='r',\n",
    "                       bbox={'facecolor':'white', 'alpha':0.6, 'pad':2})\n",
    "        else:\n",
    "            ax.annotate(world_labels_short[i], \n",
    "                        xy=(world_data_projected[i, 0]+0.01*xscale, world_data_projected[i, 1]+0.01*yscale), fontsize=10,\n",
    "                       bbox={'facecolor':'white', 'alpha':0.6, 'pad':2})\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización SOM sobre PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_data = pca_no_kernel_projection # Componentes principales de PCA sin kernel\n",
    "som_size = [30, 25]\n",
    "sm = MiniSom(som_size[0], som_size[1], som_data.shape[1], \n",
    "             sigma=np.amax(som_size)/4, sigma_final=np.amax(som_size)/10,\n",
    "             learning_rate=1.5, learning_rate_final=0.5)\n",
    "print(\"Error de cuantización (inicial): %f\" %(sm.quantization_error(som_data)))\n",
    "# Ajuste grueso\n",
    "sm.train_random(som_data, 2000)\n",
    "print(\"Error de cuantización (ajuste grueso): %f\" %(sm.quantization_error(som_data)))\n",
    "# Ajuste fino\n",
    "sm.sigma = np.amax(som_size)/10\n",
    "sm.sigma_final = 1.5\n",
    "sm.learning_rate = 0.5\n",
    "sm.learning_rate_final = 0.1\n",
    "sm.train_random(som_data, 2000)\n",
    "print(\"Error de cuantización (ajuste fino): %f\" %(sm.quantization_error(som_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# U-Matrix\n",
    "umat = sm.distance_map()\n",
    "fig = plt.figure(figsize=(12, 8)) \n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "cf = ax.contourf(umat.T, cmap=plt.cm.Spectral_r)\n",
    "plt.colorbar(cf, label='Distancia normalizada')\n",
    "plt.title('U-Matrix')\n",
    "ax.axis('off')\n",
    "for i in range(N):\n",
    "    bmu = sm.winner(som_data[i, :])\n",
    "    ax.scatter(bmu[0], bmu[1], s=2, c='k')\n",
    "    if world_labels_short[i] in countries_subset:\n",
    "        if world_labels_short[i] == \"chl\":\n",
    "            ax.annotate(world_labels_short[i], xy=(bmu[0]+0.5, bmu[1]),\n",
    "                   bbox={'facecolor':'red', 'alpha':0.6, 'pad':2})\n",
    "        else:\n",
    "            ax.annotate(world_labels_short[i], xy=(bmu[0]+0.5, bmu[1]),\n",
    "                       bbox={'facecolor':'white', 'alpha':0.6, 'pad':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización SOM sobre Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_kdata = pca_kernel_projection # Componentes principales de PCA sin kernel\n",
    "som_ksize = [30, 25]\n",
    "ksm = MiniSom(som_ksize[0], som_ksize[1], som_kdata.shape[1], \n",
    "             sigma=np.amax(som_ksize)/4, sigma_final=np.amax(som_ksize)/10,\n",
    "             learning_rate=1.5, learning_rate_final=0.5)\n",
    "print(\"Error de cuantización (inicial): %f\" %(ksm.quantization_error(som_kdata)))\n",
    "# Ajuste grueso\n",
    "ksm.train_random(som_kdata, 2000)\n",
    "print(\"Error de cuantización (ajuste grueso): %f\" %(ksm.quantization_error(som_kdata)))\n",
    "# Ajuste fino\n",
    "ksm.sigma = np.amax(som_ksize)/10\n",
    "ksm.sigma_final = 1.5\n",
    "ksm.learning_rate = 0.5\n",
    "ksm.learning_rate_final = 0.1\n",
    "ksm.train_random(som_kdata, 2000)\n",
    "print(\"Error de cuantización (ajuste fino): %f\" %(ksm.quantization_error(som_kdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Matrix\n",
    "umat = ksm.distance_map()\n",
    "fig = plt.figure(figsize=(12, 8)) \n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "cf = ax.contourf(umat.T, cmap=plt.cm.Spectral_r)\n",
    "plt.colorbar(cf, label='Distancia normalizada')\n",
    "plt.title('U-Matrix')\n",
    "ax.axis('off')\n",
    "for i in range(N):\n",
    "    bmu = ksm.winner(som_kdata[i, :])\n",
    "    ax.scatter(bmu[0], bmu[1], s=2, c='k')\n",
    "    if world_labels_short[i] in countries_subset:\n",
    "        if world_labels_short[i] == \"chl\":\n",
    "            ax.annotate(world_labels_short[i], xy=(bmu[0]+0.5, bmu[1]),\n",
    "                   bbox={'facecolor':'red', 'alpha':0.6, 'pad':2})\n",
    "        else:\n",
    "            ax.annotate(world_labels_short[i], xy=(bmu[0]+0.5, bmu[1]),\n",
    "                       bbox={'facecolor':'white', 'alpha':0.6, 'pad':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAmbios realizados\n",
    "sssssssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
